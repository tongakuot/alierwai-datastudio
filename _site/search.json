[
  {
    "objectID": "latest-articles.html",
    "href": "latest-articles.html",
    "title": "Latest Articles",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nShowcasing the dplyr case_when() and case_match() Functions\n\n\n\nData Science\n\n\nData Wrangling\n\n\nR\n\n\n\nWhile reading Effective Pandas 2 by Matt Harrison, I learned about the new .case_when method in Pandas 2, which is a total life changer for pandas users who have longed for…\n\n\n\nAlier Reng\n\n\nJan 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R\n\n\n\nData Science\n\n\nR\n\n\nData Wrangling,\n\n\nProject,\n\n\nCrime Trends,\n\n\nData Analytics\n\n\n\nIn this article, we will use Calgary crime data obtained from the Calgary website for our project. Here, you’ll find valuable insights, tutorials, and real-world examples…\n\n\n\nAlier Reng\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolving R 4 Data Science, 2nd-edition: Section 25.3.5 Exercises.\n\n\n\nData Science\n\n\nR\n\n\nTutorial\n\n\n\nTo practice R programming through hands-on exercises, as it is the best way to enhance your programming skills. In this tutorial, we will solve problems from Section 25.3.5…\n\n\n\nAlier Reng\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact us",
    "section": "",
    "text": "At ADS, our goal is to provide you with the essential skills necessary to advance your data science career. We understand that navigating through the vast amount of data science content available online can be overwhelming, and that’s why we strive to help you identify relevant and valuable information to achieve your goals. To become a successful data scientist or analyst, you need guidance and mentorship from industry experts who have demonstrated their abilities on real-world data science projects. At ADS, we offer you the opportunity to explore your potential and embark on a journey toward a fulfilling career in data science.\nEmail: info@alierwaidatastudio.com\nGitHub: @tongakuot\nFacebook: @NileQuantumInsights\nLinkedIn: @tongakuot"
  },
  {
    "objectID": "contact.html#connect-with-us",
    "href": "contact.html#connect-with-us",
    "title": "Contact us",
    "section": "",
    "text": "At ADS, our goal is to provide you with the essential skills necessary to advance your data science career. We understand that navigating through the vast amount of data science content available online can be overwhelming, and that’s why we strive to help you identify relevant and valuable information to achieve your goals. To become a successful data scientist or analyst, you need guidance and mentorship from industry experts who have demonstrated their abilities on real-world data science projects. At ADS, we offer you the opportunity to explore your potential and embark on a journey toward a fulfilling career in data science.\nEmail: info@alierwaidatastudio.com\nGitHub: @tongakuot\nFacebook: @NileQuantumInsights\nLinkedIn: @tongakuot"
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "While ADS primarily focuses on healthcare analytics, data science tutorials, statistics, and mathematics, we extend our commitment to education through personalized tutoring and mentorship services. Our comprehensive tutoring program encompasses various statistics and mathematics courses, including plane trigonometry, college algebra, finite mathematics, mathematical ideas, calculus 1 and 2, pre-calculus, and data science with R and Python. At ADS, we believe in nurturing a learning environment beyond traditional boundaries, ensuring individuals have access to the support they need to excel in their academic and professional pursuits.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "",
    "text": "I’m launching a new YouTube channel and a blog, and I’m eager to share my extensive experience in data science using R. My primary goals are to:\na) Support Aspiring Data Professionals: I aim to assist aspiring data scientists and analysts by providing valuable insights, tutorials, and practical examples using the powerful R and Python programming languages.\nb) Showcase Data Science Expertise: Through this project, I intend to showcase my expertise in managing data science projects, demonstrating the entire process from conception to completion.\nI’ve been actively using R in healthcare analytics since May 2018, and I’m excited to bring my knowledge to a broader audience through this new platform."
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#data-cleaning-and-transformation",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#data-cleaning-and-transformation",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Data Cleaning and Transformation",
    "text": "Data Cleaning and Transformation\n\nLoading the Required Libraries\nWe will utilize several essential R packages for this project, including dplyr, lubridate, purrr, tidyr, stringr, forcats, Plotly R, Crosstalk, leaflet, janitor, ggtext, gt, and gtExtras. Moreover, we will use the box package to manage our functions.\n\n# Load the necessary libraries\nbox::use(\n  plotly[...],\n  crosstalk[...],\n  dplyr[...],\n  lubridate[ym, year, month],\n  purrr[accumulate],\n  leaflet[...],\n  janitor[clean_names],\n  tidyr[...],\n  stringr[...],\n  forcats[...],\n  ggplot2[...],\n  ggtext[...],\n  gt[...],\n  gtExtras[...]\n)\n\n# Source the functions\nbox::use(modules/calc)\nbox::use(modules/plot)\n\n\n\nImporting Dataset\nIn this section, we will read in a CSV file named “Community_Crime_Statistics.csv” using the vroom package (you can also use readr to accomplish the same task) and then perform several data processing steps:\n\nClean the column names to make them more consistent and user-friendly using the clean_names() function from the janitor package.\nSelect specific columns from the dataset, specifically those from “sector” to “date” and “community_center_point.” This saves time as it eliminates the need to specify each column individually.\n\nFurther, we process the data by transforming the “category” column:\n\nConvert the text in the “category” column to sentence case (e.g., from “Break & Enter - Commercial” to “Break & enter - commercial”).\nCategorize specific values in the “category” column as “Violence” if they meet the condition of containing “non-domestic,” leaving other values unchanged.\nConvert the “sector” and “community_name” columns to the title case (e.g., from “NORTHWEST” to “Northwest”).\n\n\n\n\n\n\n\nTip\n\n\n\nOverall, we prepare and clean the data in the “calgary_raw” dataset for further analysis and visualization by renaming columns and transforming values in the “category,” “sector,” and “community_name” columns.\n\n\n\n# Load the dataset\ncalgary_raw &lt;- vroom::vroom(\n  \"Community_Crime_Statistics.csv\",\n  show_col_types = FALSE\n) |&gt;\n  # Clean column names\n  clean_names() |&gt;\n  # Select desired columns: we use intervals by column names\n  select(sector:date, community_center_point) |&gt;\n  mutate(\n    category = str_to_sentence(category),\n    category = case_when(\n      str_detect(category, \"non-domestic\") ~ \"Violence\",\n      .default = category\n    ),\n    sector = str_to_title(sector),\n    community_name = str_to_title(community_name)\n  )"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#data-summary-and-exploration",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#data-summary-and-exploration",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Data Summary and Exploration",
    "text": "Data Summary and Exploration\nIn this section, I will perform a quick data summary and exploration by piping the “calgary_raw” dataset into the skim() function from the skimr package. The skimr package lets us quickly summarize the dataset to gain insights into its structure, data types, missing values, and statistical summaries of numeric columns.\nThe skim() function creates a data summary report that includes information such as the number of observations, the number of variables (columns), the data type of each variable, the number of missing values, and various summary statistics for numeric variables, including mean, median, standard deviation, and more.\nThis summary is useful for initial data exploration, as it helps us to quickly understand the characteristics and quality of the dataset, identify potential issues or outliers, and determine the next steps for data analysis or cleaning. It’s a helpful tool in the early stages of data analysis to get an overview of the data’s structure and contents.\n\ncalgary_raw |&gt; \n  skimr::skim()\n\n\nData summary\n\n\nName\ncalgary_raw\n\n\nNumber of rows\n79982\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nsector\n181\n1\n4\n9\n0\n8\n0\n\n\ncommunity_name\n0\n1\n3\n29\n0\n316\n0\n\n\ncategory\n0\n1\n8\n30\n0\n8\n0\n\n\ndate\n0\n1\n7\n7\n0\n80\n0\n\n\ncommunity_center_point\n181\n1\n29\n46\n0\n1024\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncrime_count\n1\n1\n2.83\n3.62\n1\n1\n2\n3\n110\n▇▁▁▁▁"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#group-by-and-summarization",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#group-by-and-summarization",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Group By and Summarization",
    "text": "Group By and Summarization\nIn this section, our primary focus is on creating a refined dataset named “calgary_tbl” from the original “calgary_raw” dataset. To accomplish this, we implement several key data processing steps.\n\nColumn Splitting: We begin by splitting the “community_center_point” column into three separate columns: “NA,” “lon,” and “lat.” This transformation is achieved using the “separate_wider_delim()” function, which automatically drops specified columns marked as “NA.” This function is a more robust alternative to the traditional “separate()” function in the tidyr package. Any rows with excessive values are automatically excluded during this process by setting “too_many” to “drop.”\nIdentifying Non-Standard Community Names: We identify non-standard community names by applying a regular expression check to determine if the “community_name” begins with a non-digit character, such as special characters or letters. These rows are labeled as “wanted_rows” because they represent the correct community names. In essence, we filter out all non-standard community names.\n\nDate Standardization and Cleaning: We proceed by converting the “date” column into a standardized date format and extracting the year from it. We then combine the year with the month to create a new “date” column in the “YYYY-MMM” format. Additionally, we remove any parentheses from the “lon” and “lat” columns to cleanse the data of unwanted characters.\nData Quality Assurance: To ensure data quality, we filter the dataset by removing rows with missing values in the “sector” column and rows featuring non-standard community names that lack a numeric starting character, as described earlier.\nGrouping and Summarization: We group the data by “sector,” “category,” “year,” “date,” “lon,” and “lat.” Importantly, we include “lon” and “lat” in the “.by()” function to obtain distinct longitude and latitude values for each sector and community name. Subsequently, we calculate the sum of “crime” for each group and exclude missing values when applicable.\nDataset Review: Finally, we review the refined dataset, “calgary_tbl,” by inspecting the top 5 rows using the “slice_head()” function and present the output in a well-organized table format using “knitr::kable()”.\n\n\n\n\nIt’s worth noting that we’ve replaced “separate()” with “separate_wider_position()” and “separate_wider_delim()” due to their enhanced clarity, improved API, and superior handling of potential issues.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis code streamlines and enhances the “calgary_raw” dataset by addressing missing values, adjusting data types, and aggregating crime counts. Furthermore, it ensures data quality and provides a convenient means of inspecting the refined dataset.\nOverall, the provided details offer a comprehensive view of the data preparation steps and their significance in the analysis.\n\n\n\n\n# Subset the data\ncalgary_tbl &lt;-\n  calgary_raw |&gt;\n  separate_wider_delim(\n    community_center_point,\n    delim = \" \",\n    names = c(NA, \"lon\", \"lat\"),\n    too_many = \"drop\"\n  ) |&gt;\n  # Identify non-standard community names\n  mutate(\n    wanted_rows = str_detect(community_name, \"^\\\\D\"),\n    date = ym(date),\n    year = year(date),\n    date = str_c(year(date), \"-\", month(date, label = TRUE)),\n    lon = str_remove_all(lon, \"\\\\(\"),\n    lat = str_remove_all(lat, \"\\\\)\")\n  ) |&gt;\n  # Drop rows with nas: 181 rows; non-standard community names: 1026 rows\n  filter(!is.na(sector), wanted_rows) |&gt;\n  # Group by and summarization\n  calc$summarize_calgary_crime_data(\n    crime_var = crime_count,\n    group_var = c(sector:category, year, date, lon, lat)\n  )\n\n# Inspect the top\ncalgary_tbl |&gt;\n  slice_head(n = 5) |&gt;\n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsector\ncommunity_name\ncategory\nyear\ndate\nlon\nlat\ncrime\n\n\n\n\nNortheast\nAbbeydale\nViolence\n2022\n2022-Apr\n-113.927803856151\n51.059415006964\n1\n\n\nNortheast\nAbbeydale\nBreak & enter - commercial\n2022\n2022-Apr\n-113.927803856151\n51.059415006964\n2\n\n\nNortheast\nAbbeydale\nBreak & enter - other premises\n2022\n2022-Apr\n-113.927803856151\n51.059415006964\n1\n\n\nNortheast\nAbbeydale\nTheft from vehicle\n2022\n2022-Apr\n-113.927803856151\n51.059415006964\n5\n\n\nNortheast\nAbbeydale\nTheft of vehicle\n2022\n2022-Apr\n-113.927803856151\n51.059415006964\n4"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgary-crime-data-with-ggplot2-package",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgary-crime-data-with-ggplot2-package",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Visualizing Calgary Crime Data with ggplot2 Package",
    "text": "Visualizing Calgary Crime Data with ggplot2 Package\nWith our dataset now cleaned and transformed, we embark on exploratory data analysis (EDA) using the ggplot2 and ggtext packages. Our first step is to create a data plot based on the year, defining color aesthetics using the Sector column.\nHere, we assign a label (“fig-ggplot_1”) to distinguish our plot from subsequent plots and provide a caption for the figure titled “Calgary Crime Activities by Sector & Year.” Subsequently, we process and summarize crime data in Calgary to obtain crime counts by Sector and Year, naming this resulting dataset “sector_crime.” Then, we generate a plot with the crime count on the x-axis and the year on the y-axis, with the years presented in reverse order.\nA brief analysis of our plot reveals that the “Centre Sector” consistently reports the highest number of crime activities each year.\n\n# Crime count by sector\nsector_crime &lt;-\n  calgary_tbl |&gt;\n  calc$summarize_calgary_crime_data(\n    crime_var = crime,\n    group_vars = c(sector, year)\n  )\n\n# Plot crime count by year\nsector_crime_g &lt;-\n  sector_crime |&gt;\n  plot$plot_calgary_crime_data(\n    x_var = crime,\n    y_var = year |&gt; factor() |&gt; fct_rev(),\n    max_var = 15000,\n    step_var = 5000,\n    fill_var = sector,\n    x = \"Crime Count\",\n    y = NULL,\n    fill_text = \"Sector\",\n    title = \"Centre Sector leads all the Sectors in Number of Crime Activities.\"\n  )\n\n#Print the plot\nsector_crime_g\n\n\n\n\nFigure 1: Calgary Crime Activities by Sector & Year\n\n\n\n\nIn this section, we summarize the dataset by Sector and Crime category and then plot it with the Category on the y-axis and the crime count on the x-axis for better visualization. Once again, we observe that the Centre Sector leads in all categories of crime activities, except for ‘Theft of Vehicle.’\n\n# Crime count by sector & category\ncategory &lt;- calgary_tbl |&gt;\n  mutate(category = str_wrap(category, width = 15)) |&gt;\n  calc$summarize_calgary_crime_data(\n    crime_var = crime,\n    group_vars = c(sector, category)\n  )\n\n# Plot Crime activties by sector & category\ncat_g &lt;-\n  category |&gt;\n  plot$plot_calgary_crime_data(\n    x_var = crime,\n    y_var = category,\n    max_var = 30000,\n    step_var = 5000,\n    fill_var = sector,\n    x = \"Crime Count\",\n    y = NULL,\n    fill = \"Sector\",\n    title = \"The Centre Sector leads in all categories of crime activities except for 'Theft of Vehicle'.\"\n  )\n\n# Display the plot\ncat_g\n\n\n\n\nFigure 2: Calgary Crime Activities by Sector & Category"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#tabulating-calgary-crime-activities-by-sector-and-category",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#tabulating-calgary-crime-activities-by-sector-and-category",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Tabulating Calgary Crime Activities by Sector and Category",
    "text": "Tabulating Calgary Crime Activities by Sector and Category\nIn this section, we organize the dataset obtained in the previous section and create a table using the gt and gtExtras packages. Our previous findings remain consistent – except for ‘Theft of Vehicle,’ the Centre Sector continues to exhibit the highest counts of crime activities.\n\n\n\n\n\n\nTip\n\n\n\nIt’s worth noting that we used the relocate() function from the dplyr package to reorder columns. We used relocate() to demonstrate its functionality, but achieving the same task using the select() function is also possible.\n\n\n\n# Tabulate the data\n# -----------------\ntable_obj &lt;-\n  category |&gt;\n  pivot_wider(\n    names_from = category,\n    values_from = crime\n  ) |&gt;\n  clean_names() |&gt;\n  relocate(\n    c(commercial_robbery),\n    .after = 3\n  ) |&gt;\n  relocate(\n    break_enter_dwelling,\n    .after = break_enter_other_premises\n  ) |&gt;\n  relocate(\n    street_robbery,\n    .after = commercial_robbery\n  ) |&gt;\n  relocate(\n    theft_of_vehicle,\n    .after = theft_from_vehicle\n  ) |&gt;\n  relocate(violence, .after = 1) |&gt;\n  arrange(desc(violence))\n\n\n# Initialize the table\ntable_obj |&gt;\n  gt(rowname_col = \"sector\") |&gt;\n  cols_align(\n    columns = where(is.numeric),\n    align = \"center\"\n  ) |&gt;\n  cols_align(\n    columns = sector,\n    align = \"right\"\n  ) |&gt;\n  fmt_integer() |&gt;\n  cols_label(\n    commercial_robbery = \"Commercial\",\n    break_enter_commercial = \"Commercial\",\n    break_enter_other_premises = \"Premises\",\n    break_enter_dwelling = \"Dwelling\",\n    theft_from_vehicle = \"From Vehicle\",\n    theft_of_vehicle = \"Of Vehicle\",\n    street_robbery = \"Street\"\n  ) |&gt;\n  tab_spanner(\n    label = \"Non-Domestic\",\n    columns = 2\n  ) |&gt;\n  tab_spanner(\n    label = \"Theft\",\n    columns = 3:4\n  ) |&gt;\n  tab_spanner(\n    label = \"Robbery\",\n    columns = 5:6\n  ) |&gt;\n  tab_spanner(\n    label = \"Break & Enter\",\n    columns = 7:9\n  ) |&gt;\n  gt_theme_espn() |&gt;\n  tab_header(\n    title = \"The Centre Sector leads in all categories of crime activities except for 'Theft of Vehicle'.\"\n  ) |&gt;\n  tab_footnote(\n    footnote = md(\"Data obtained from: [Calgary Crime Data](https://data.calgary.ca/Health-and-Safety/Community-Crime-Statistics/78gh-n26t)\")\n  )\n\n\n\n\n\nTable 1:  Calgary Crime Activities by Sector \n  \n    \n      The Centre Sector leads in all categories of crime activities except for 'Theft of Vehicle'.\n    \n    \n    \n      \n      \n        Non-Domestic\n      \n      \n        Theft\n      \n      \n        Robbery\n      \n      \n        Break & Enter\n      \n    \n    \n      violence\n      Commercial\n      Commercial\n      Street\n      Premises\n      Dwelling\n      From Vehicle\n      Of Vehicle\n    \n  \n  \n    Centre\n16,028\n13,208\n599\n1,294\n5,385\n2,909\n26,065\n8,479\n    Northeast\n8,412\n3,925\n497\n1,054\n2,177\n1,830\n14,991\n9,812\n    South\n5,165\n2,928\n267\n316\n1,725\n1,964\n11,162\n3,916\n    East\n3,979\n2,252\n210\n447\n1,090\n800\n5,722\n3,992\n    Northwest\n3,862\n2,033\n223\n269\n1,248\n1,918\n7,713\n2,683\n    North\n2,903\n1,431\n161\n220\n791\n1,490\n5,677\n2,766\n    West\n2,600\n1,454\n178\n223\n819\n1,527\n4,924\n1,614\n    Southeast\n2,446\n1,738\n94\n107\n518\n1,082\n4,887\n2,301\n  \n  \n  \n    \n       Data obtained from: Calgary Crime Data"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgary-crime-activities-with-the-leaflet-package",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgary-crime-activities-with-the-leaflet-package",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Visualizing Calgary Crime Activities with the leaflet Package",
    "text": "Visualizing Calgary Crime Activities with the leaflet Package\nIn this section, we leverage the leaflet package to visually represent crime activities within Calgary’s communities. This marks my inaugural use of this package, and I extend my gratitude to DataCamp.com for their invaluable courses.\nOur initial step involves creating a data frame named map_data by summarizing the calgary_tbl dataset, which has been a focal point in our previous sections. We group this data by sector and community name, subsequently calculating the total count of crimes. Additionally, we determine the mean longitude (lon) and latitude (lat) for each community. This meticulous approach guarantees that we possess unique longitude and latitude values for every community.\nFollowing this data preparation, we introduce map_data into a leaflet canvas to initiate the map visualization process. We augment the canvas with a tile layer furnished by the “CartoDB” provider, although there exist various provider options catering to individual preferences.\nSubsequently, we enhance our map’s customization by utilizing the clearMarkers() function to eliminate any previously added markers. To replace them, we introduce circular markers onto the map, configuring them with a radius of 5, an orange color scheme, and labels denoting the community name and the corresponding crime count enclosed in parentheses.\nOur overarching goal in this section and the subsequent one is to offer a visually intuitive representation of the data, facilitating a better understanding of the distribution of crime activities across different areas.\n\nmap_data &lt;-\n  calgary_tbl |&gt;\n  group_by(sector, community_name) |&gt;\n  summarise(\n    crime = sum(crime),\n    lon = mean(as.numeric(lon)),\n    lat = mean(as.numeric(lat))\n  )\n\nmap_data |&gt;\n  leaflet() |&gt;\n  addProviderTiles(\"CartoDB\") |&gt;\n  addMarkers(lng = ~lon, lat = ~lat) |&gt;\n  clearMarkers() |&gt;\n  addCircleMarkers(\n    lng = ~lon,\n    lat = ~lat,\n    radius = 5,\n    color = ~\"#EA650D\",\n    label = ~ paste0(community_name, \" (\", crime, \")\")\n  )\n\n\n\nCalgary Crime Activities by Community\n\n\n\n# Wrap data frame in SharedData\ncommunity_data &lt;-\n  calgary_tbl |&gt;\n  mutate(\n    year_month = date,\n    date = ym(date)\n  ) |&gt;\n  summarize(\n    crime = sum(crime),\n    lon = mean(as.numeric(lon)),\n    lat = mean(as.numeric(lat)),\n    .by = c(sector, year)\n  )\n\ncrime_activities_by_sector &lt;-\n  community_data |&gt;\n  SharedData$new(key = ~sector)\n\n\n# Use SharedData like a dataframe with Crosstalk-enabled widgets\nleaflet(crime_activities_by_sector) |&gt;\n  addTiles() |&gt;\n  addMarkers(lng = ~lon, lat = ~lat)\n\n\n\nCrime Activities by Sector"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#plotting-a-line-graph-with-the-plotly-r-package",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#plotting-a-line-graph-with-the-plotly-r-package",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Plotting a Line Graph with the Plotly R Package",
    "text": "Plotting a Line Graph with the Plotly R Package\nIn this section, we turn to one of the most potent tools in data science visualization, the Plotly R package, to visualize our Calgary crime dataset. We commence by subsetting data from the calgary_tbl dataset. To enhance data analysis, we transform the date column into a new one named “year_month” and convert the original date column into a year-month format using the ym() function from the lubridate package.\nSubsequently, we employ our custom function, summarize_calgary_crime_data, to calculate the total crime counts, grouping the data by sector, date, and year_month. We assign the resulting dataset to the “community” data frame.\nThe next step involves creating a line graph using the Plotly R package to visually represent the crime trend in Calgary over time. We place the date on the x-axis and the crime count on the y-axis, with color indicating different sectors. Additionally, we implement a tooltip text displaying sector, date, and crime count. We set the axis breaks to intervals of three months using the “dtick” argument, along with other labeling adjustments in the layout.\n\n\nThe generated Plotly line graph visualizes crime activities in Calgary by sector and month, offering valuable insights into trends from January 1, 2017, to September 30, 2023.\nOur analysis of crime activities by Sector and month reveals that the Centre and Northeast sectors exhibit higher trends in crime activities. Notably, all Calgary communities experienced fluctuation in crime activities throughout the past 6 plus years. Furthermore, the West Sector consistently maintains the lowest crime activities among all Calgary communities. Additionally, the Northwest overtook the East Sector in October 2021 and remained higher until April 2023.\n\n# Subset the data\ncommunity &lt;-\n  calgary_tbl |&gt;\n  mutate(\n    year_month = date,\n    date = ym(date)\n  ) |&gt;\n  calc$summarize_calgary_crime_data(\n    crime_var = sum(crime),\n    group_vars = c(sector, date, year_month)\n  )\n\n# Plot a line graph with plotly\nplotly_g &lt;-\n  community |&gt;\n  plot_ly(\n    x = ~date,\n    y = ~crime,\n    color = ~sector,\n    hoverinfo = \"text\",\n    text = ~ paste0(\n      \"Sector:\", sector, \"&lt;br&gt;\",\n      \"Date:\", year_month, \"&lt;br&gt;\",\n      \"Crime Count:\", crime\n    )\n  ) |&gt;\n  add_lines(colors = \"Dark2\", name = ~sector) |&gt;\n  layout(\n    xaxis = list(\n      title = \"\",\n      dtick = \"M3\",\n      tickformat = \"%Y&lt;br&gt;%b\",\n      width = 1000\n    ),\n    yaxis = list(title = \"Crime Count\"),\n    title = \"Calgary Crime Activities Fluctuate between January 1, 2017 to September 30, 2023\"\n  )\n\nplotly_g\n\n\n\n\nFigure 3: Calgary Crime Activities by Sector and Month"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgarys-crime-activities-by-month-and-category",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#visualizing-calgarys-crime-activities-by-month-and-category",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Visualizing Calgary’s Crime Activities by Month and Category",
    "text": "Visualizing Calgary’s Crime Activities by Month and Category\nIn this section, we craft a dynamic plot to visualize crime activities in Calgary, categorized by both month and crime type. For improved representation, we classify crime incidents into broader categories, such as “Robbery,” “Theft,” “Break & Enter,” and “Violence,” using a case_when() statement based on the content of the “category” column.\nOnce the data is transformed, we calculate the total sum of crime incidents by grouping the data based on both the date and the new category, naming the resulting data frame “crime_cat.”\nNext, we create an interactive plot using the Plotly R package. This plot illustrates the trend of crime activities in Calgary over time, organized by different crime types. The x-axis showcases the date, while the y-axis indicates the crime count. To provide additional information, we incorporate tooltips displaying details about the category, date, and crime count for each data point.\nOur analysis of Calagry Crime Activities by Month & Category reveal that robbery activities, both commercial and street, have consistently remained at lower levels compared to other crime categories over the past 6.75 years. In contrast, theft (both from and of vehicles) has always maintained high levels. Furthermore, after a brief decline between October 2020 and February 2021, Calgary’s crime activities began to increase, but they appear to decline again toward the end of 2023. Additionally, non-domestic violence surpassed break & enter in January 2022 and has stayed above ever since.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe resulting dynamic plot, labeled “Calgary Crime Activities by Month & Category,” offers a visual representation of how crime activities in Calgary have evolved over time, categorized by specific crime types from January 1, 2017, to September 30, 2023. The graph enables viewers to explore and analyze crime trends within various categories throughout the specified time period.\n\n\n\n# Create a dynamic plot\ncrime_cat &lt;-\n  calgary_tbl |&gt;\n  mutate(\n    date = ym(date),\n    category = case_when(\n      str_detect(category, \"robbery\") ~ \"Robbery\",\n      str_detect(category, \"Theft\") ~ \"Theft\",\n      str_detect(category, \"Break & enter\") ~ \"Break & Enter\",\n      TRUE ~ \"Violence\"\n    )\n  ) |&gt;\n  calc$summarize_calgary_crime_data(\n    crime_var = sum(crime),\n    group_vars = c(date, category)\n  )\n\ncat_g &lt;- crime_cat |&gt;\n  plot_ly(\n    x = ~date, y = ~crime,\n    hoverinfo = \"text\",\n    text = ~ paste0(\n      \"Category:\", category, \"&lt;br&gt;\",\n      \"Date:\", date, \"&lt;br&gt;\",\n      \"Crime Count:\", crime\n    )\n  ) |&gt;\n  add_lines(color = ~category) |&gt;\n  layout(\n    xaxis = list(\n      title = \"\",\n      dtick = \"M3\",\n      tickformat = \"%Y&lt;br&gt;%b\",\n      width = 1000\n    ),\n    yaxis = list(title = \"Crime Count\"),\n    title = \"Calgary Crime Trend (January 1, 2017 to August 31, 2023\"\n  )\n\ncat_g\n\n\n\n\nFigure 4: Calagry Crime Activities by Month & Category"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#harnessing-the-powers-of-plotly-r-and-crosstalk-packages",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#harnessing-the-powers-of-plotly-r-and-crosstalk-packages",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Harnessing the Powers of Plotly R and Crosstalk Packages",
    "text": "Harnessing the Powers of Plotly R and Crosstalk Packages\nIn this section, we harness the capabilities of the Plotly R and Crosstalk packages to create dynamic visualizations of crime activities in Calgary. First, we group the crime dataset by sector, year, and category, calculate the sum of crime counts in each sector, and name the new data frame “sector_dynamic.”\nNext, we create a shared data object, “shared_sector,” keyed by the sector, to facilitate synchronized interactions between multiple visualizations.\nTo plot interactive joint bar and scatter plots, we generate a bar chart, “bar_chart,” that displays the frequency of crime activities by sector. The sector is plotted on the x-axis, and the frequency of crime activities is shown on the y-axis. Additionally, we create a bubble chart, “bubble_chart,” to visualize the relationship between crime activities and years for each sector. This scatterplot uses bubbles to represent the data points and color-codes them by crime category. The x-axis represents the year, the y-axis represents the crime count, and tooltips provide information about the crime category. Finally, we remove the legend from both the bar chart and bubble chart to declutter the visualizations.\n\n# Create a dynamic plot\nsector_dynamic &lt;-\n  calgary_tbl |&gt;\n  calc$summarize_calgary_crime_data(\n    crime_var = crime,\n    group_vars = c(sector, year, category)\n  )\n\n# Create a shared data object keyed by sector\nshared_sector &lt;- sector_dynamic |&gt;\n  SharedData$new(key = ~sector)\n\n# Create a sector bar chart\nbar_chart &lt;- shared_sector |&gt;\n  plot_ly() |&gt;\n  group_by(sector) |&gt;\n  summarize(crime = sum(crime)) |&gt;\n  # arrange(desc(crime)) |&gt;\n  add_bars(x = ~sector, y = ~crime) |&gt;\n  layout(\n    barmode = \"overlay\",\n    xaxis = list(title = \"Sector\"),\n    yaxis = list(title = \"Frequency of Crime Activities\")\n  )\n\n# Create a sector bubble chart\nbubble_chart &lt;- shared_sector |&gt;\n  plot_ly(\n    x = ~year,\n    y = ~crime,\n    hoverinfo = \"text\",\n    text = ~category,\n    color = ~category\n  ) |&gt;\n  add_markers(marker = list(sizemode = \"diameter\")) |&gt;\n  hide_legend() |&gt;\n  layout(\n    xaxis = list(title = \"\"),\n    yaxis = list(title = \"\")\n  )\n\n# Remove the legend\nbscols(bar_chart, bubble_chart) |&gt;\n  hide_legend()"
  },
  {
    "objectID": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#key-findings",
    "href": "case-studies/posts/2023/10/18/calgary_crime_analysis.html#key-findings",
    "title": "Navigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R",
    "section": "Key Findings:",
    "text": "Key Findings:\nIn our analysis of crime activities by Sector and Month, we discovered that the Centre and Northeast sectors exhibited higher trends in crime activities. Notably, all Calgary communities experienced fluctuations in crime activities throughout the past 6-plus years, while the West Sector consistently maintained the lowest crime activities among all Calgary communities. Additionally, the Northwest overtook the East Sector in October 2021 and remained higher until April 2023.\nOur examination of Calgary Crime Activities by Month and Category revealed intriguing trends. Robbery activities, both commercial and street, consistently remained at lower levels than other crime categories over the past 6.75 years. In contrast, theft (both from and of vehicles) always maintained high levels. Furthermore, after a brief decline between October 2020 and February 2021, Calgary’s crime activities began to increase, but they appear to be declining again toward the end of 2023. Additionally, non-domestic violence surpassed break & enter in January 2022 and has remained above ever since.\nIn conclusion, this project embodies my commitment to supporting aspiring data professionals and showcasing my data science expertise. Whether you are embarking on your data science journey or looking to enhance your skills, my content will equip you with the tools and knowledge needed to effectively tackle data science projects.\nTogether, we have unveiled the boundless possibilities the world of data science in R offers. I invite you to join me on this exhilarating journey through the art and science of data, where we can continue exploring the captivating realm of data science with unwavering confidence. To explore more in-depth tutorials and engage with our community, I invite you to follow my YouTube channel (@AlierwaiDataStudio) and blog (www.alierwai.org), where our data science adventure continues."
  },
  {
    "objectID": "case-studies/index.html",
    "href": "case-studies/index.html",
    "title": "Case studies",
    "section": "",
    "text": "At ADS, we take pride in showcasing our data science expertise through impactful case studies using real-world data. In the 21st century, where word of mouth alone is insufficient, we understand the importance of providing practical examples. On this page, our work speaks for itself, demonstrating what we know and how our data solutions and services deliver tangible value. These case studies are more than just projects; they are a testament to our commitment to excellence and a foundation for building trust in our capabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Data Science: A Comprehensive Analysis of Calgary Crime Data using R\n\n\n\nData Science\n\n\nR\n\n\nData Wrangling,\n\n\nProject,\n\n\nCrime Trends,\n\n\nData Analytics\n\n\n\nIn this article, we will use Calgary crime data obtained from the Calgary website for our project. Here, you’ll find valuable insights, tutorials, and real-world examples…\n\n\n\nAlier Reng\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about-us.html",
    "href": "about-us.html",
    "title": "Welcome to Alierwai DataStudio!",
    "section": "",
    "text": "Alierwai DataStudio is a platform for knowledge sharing and continuous learning. With a focus on data science tutorials, statistics, and mathematics, it aims to inspire and empower individuals to enhance their skills and achieve their goals.\nI am deeply passionate about the transformative power of data science, healthcare analytics, and statistics. With proficiency in R and Python programming languages, I aspire to make a positive impact on the lives of individuals worldwide, especially in my home country of South Sudan. Despite limited resources, I am committed to helping others learn data science, statistics, and mathematics from anywhere, at any time. Through my exceptional tutoring and mentorship services, I aim to empower individuals to achieve their data science goals and secure promising career opportunities in today’s rapidly evolving job market."
  },
  {
    "objectID": "about-us.html#mission-statement",
    "href": "about-us.html#mission-statement",
    "title": "Welcome to Alierwai DataStudio!",
    "section": "Mission Statement",
    "text": "Mission Statement\nPromoting data literacy through advanced training, consulting, tutoring in statistics and mathematics, and mentorship."
  },
  {
    "objectID": "about-us.html#vision-statement",
    "href": "about-us.html#vision-statement",
    "title": "Welcome to Alierwai DataStudio!",
    "section": "Vision Statement",
    "text": "Vision Statement\nI strive to impart knowledge and train the next generation of data scientists and analysts to help them unlock their full potential and positively impact the world."
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "",
    "text": "While reading Effective Pandas 2 by Matt Harrison, I learned about the new .case_when() method in Pandas 2, which is a total life changer for pandas users who have longed for such a function for a long time. However, as an R programmer, I decided to review the dplyr case_when() documentation and learned that this lifesaving function has been updated. The recently released version of the case_when() function now includes the following arguments:\n\ncase_when(…, .default = NULL, .ptype = NULL, .size = NULL)\n\nYou can read more about case_when() function here!"
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html#loading-the-required-libraries",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html#loading-the-required-libraries",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "Loading the Required Libraries",
    "text": "Loading the Required Libraries\nWe will load the entire tidyverse meta-package (which contains 9 packages) for this tutorial, although we will only use the dplyr, tidyr, and stringr packages. Additionally, we will suppress warnings and notifications by setting the warning and message options to false, respectively.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html#loading-the-dataset",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html#loading-the-dataset",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "Loading the dataset",
    "text": "Loading the dataset\nWe will use the vroom package instead of the readr package to load the South Sudan 2008 census dataset. Even though our dataset is too small for the speed to matter, vroom is faster than readr.\n\n# Load the data -----------------\nssd_census_2008 &lt;-\n  vroom::vroom(\n    \"ss_2008_census_data_raw.csv\",\n    show_col_types = FALSE\n  ) |&gt;\n  select(\n    state        = `Region Name`,\n    gender       = `Variable Name`,\n    age_category = `Age Name`,\n    population   = `2008`\n  ) |&gt;\n  filter(\n    !is.na(gender),\n    age_category != \"Total\"\n  )"
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html#tidying-column-values-with-the-separate-variants",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html#tidying-column-values-with-the-separate-variants",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "Tidying Column Values with the separate() variants",
    "text": "Tidying Column Values with the separate() variants\nIn this section, we’ll demonstrate how to use the separate_wider_delim() function, the most commonly used of the two variants of the separate() function. First, we will show how we solved the same problem previously and then show the updated variant.\n\nWe are trying to solve\nHere, we aim to separate the gender column into three new columns but only keep the middle column with gender rows. Here are the unique values currently in the gender column: “Population, Total (Number),” “Population, Male (Number),” and “Population, Female (Number).”"
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html#before",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html#before",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "Before",
    "text": "Before\n\n# Showcase the separate() function\nseparate_before_tbl &lt;-\n  case_match_tbl |&gt;\n  # Split gender column into: pop, gender, and other\n  separate(\n    col = gender, \n    into = c(\"pop\", \"gender\", \"other\"), \n    sep = \" \"\n  ) |&gt;\n  # Remove extra/unwanted columns\n  select(-pop, -other) |&gt; \n  # Remove the total rows\n  filter(gender != \"Total\") |&gt;\n  # Group by and summarization\n  summarize(\n    population = sum(population),\n    .by = c(former_region, state, gender, age_category)\n  )\n\nThe separate() function handles additional pieces with the extra argument, which can be set to either “warn,” “drop,” or “merge.” However, if there are fewer pieces, then separate() handles them with the fill argument, which can be set to either “warn” (this is the default option; it emits a warning and fills in the missing pieces from the right), “right” (‘fill with missing values on the right’), and “left” (‘fill with missing values on the left’)."
  },
  {
    "objectID": "tutorials/posts/2024/01/04/tutorial-02.html#now",
    "href": "tutorials/posts/2024/01/04/tutorial-02.html#now",
    "title": "Showcasing the dplyr case_when() and case_match() Functions",
    "section": "Now",
    "text": "Now\n\n# Showcase the separate() function\nseparate_wider_delim_tbl &lt;-\n  case_match_tbl |&gt;\n  # Split gender column\n  separate_wider_delim(\n    gender,\n    delim    = \" \",\n    names    = c(NA, \"gender\"),\n    too_many = \"drop\" # drop extra column\n  ) |&gt;\n  # Remove the total rows\n  filter(gender != \"Total\") |&gt;\n  # Group by and summarization\n  summarize(\n    population = sum(population),\n    .by = c(former_region, state, gender, age_category)\n  )"
  },
  {
    "objectID": "tutorials/posts/2023/11/11/tutorial-01.html",
    "href": "tutorials/posts/2023/11/11/tutorial-01.html",
    "title": "Solving R 4 Data Science, 2nd-edition: Section 25.3.5 Exercises.",
    "section": "",
    "text": "Motivation\nTo practice R programming through hands-on exercises, as it is the best way to enhance your programming skills.\nIn this tutorial, we will solve problems from Section 25.3.5 of the famous R 4 Data Science by Hadley Wickham et al. Let’s get started!\n\n\nLoading Required Libraries\nIn this section, we will load tidyverse and nycflights13 packages. We will set warning and message to false to suppress warnings and notifications.\n\n# Libraries\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n\n\nSection 25.3.5 Exercises\n\nUsing the datasets from nycflights13, write a function that:\n\n\nFinds all flights that were cancelled (i.e. is.na(arr_time)) or delayed by more than an hour. About the author\n\n\n # Subset flights data\ncanceled_or_delayed_flights &lt;- \n    flights |&gt;\n  filter(is.na(arr_time) | dep_delay &gt; 1)\n\n# Write a function\nfilter_severe &lt;- function(data, condition) {\n  data |&gt;\n    filter({{ condition }})\n}\n\n# Let's test our function\ncanceled_or_delayed_flights &lt;- \n    flights |&gt; \n    filter_severe(is.na(arr_time) | dep_delay &gt; 1)\n\n# Display the results\ncanceled_or_delayed_flights |&gt; \n    slice_head(n = 5) |&gt; \n    knitr::kable(align = \"c\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n\n2013\n1\n1\n517\n515\n2\n830\n819\n11\nUA\n1545\nN14228\nEWR\nIAH\n227\n1400\n5\n15\n2013-01-01 05:00:00\n\n\n2013\n1\n1\n533\n529\n4\n850\n830\n20\nUA\n1714\nN24211\nLGA\nIAH\n227\n1416\n5\n29\n2013-01-01 05:00:00\n\n\n2013\n1\n1\n542\n540\n2\n923\n850\n33\nAA\n1141\nN619AA\nJFK\nMIA\n160\n1089\n5\n40\n2013-01-01 05:00:00\n\n\n2013\n1\n1\n608\n600\n8\n807\n735\n32\nMQ\n3768\nN9EAMQ\nEWR\nORD\n139\n719\n6\n0\n2013-01-01 06:00:00\n\n\n2013\n1\n1\n611\n600\n11\n945\n931\n14\nUA\n303\nN532UA\nJFK\nSFO\n366\n2586\n6\n0\n2013-01-01 06:00:00\n\n\n\n\n\nIn the code snippet above, we first wrote the code for solving the problem and then converted our code into a function as instructed. Next, we tested our function to ensure that it works as expected.\n\nCounts the number of cancelled flights and the number of flights delayed by more than an hour.\n\n\n# Write a function\nsummarize_severe &lt;- function(data, var) {\n  data |&gt;\n    summarize(\n      n = sum({{ var }})\n    )\n}\n\n# Test the function\ndf_0 &lt;- flights |&gt;\n  group_by(dest) |&gt;\n  summarize_severe(is.na(arr_time) | dep_delay &gt; 1)\n\n# OR ------------------------------------------------\n\n# We could do this:\nsummarise_severe &lt;- function(data, group_var, var) {\n  data |&gt;\n    summarize(\n      total = sum({{ var }}),\n      .by = {{ group_var }}\n    )\n}\n\n# Test the second function\ndf_1 &lt;-\n  summarise_severe(\n    flights,\n    var = c(is.na(arr_time) | dep_delay &gt; 1),\n    group_var = dest\n  )\n\nIn the code snippet above, we solved a problem using two approaches. Firstly, we defined the function summarize_severe() and used it along with the group_by() function to calculate the total number of canceled flights and flights delayed by over one hour. Secondly, we defined the function summarise_severe() and used it with the .by argument in the summarize() function to calculate the same total.\nWe observed that both approaches produced similar results (we prefer the approach with the .by argument).\n\nFinds all flights that were cancelled or delayed by more than a user supplied number of hours.\nWe solved the question below with our filter function, filter_severe(), from problem 1 above.\n\n\n# Use a user supplied number of hours\ndf_with_user_supplied_hours &lt;-\n  flights |&gt;\n  filter_severe(\n    is.na(arr_time) | dep_delay &gt; 2\n  )\n\n\nSummarizes the weather to compute the minimum, mean, and maximum, of a user supplied variable:\n\n\n\n\n\n\n\n\n\nHint\n\n\n\nBy default, across() renames resulting columns with the pattern: {function}{column_name}, for example, temp_min. You can override this behavior by setting the .names option to “{.fn}{.col}”.\n\n\n\n# Solution\nweather |&gt;\n  summarize(\n    # Temperature \n    min_temp  = min(temp, na.rm = TRUE),\n    mean_temp = mean(temp, na.rm = TRUE),\n    max_temp  = max(temp, na.rm = TRUE),\n    \n    # Pressure\n    min_pressure  = min(pressure, na.rm = TRUE),\n    mean_pressure = mean(pressure, na.rm = TRUE),\n    max_pressure  = max(pressure, na.rm = TRUE),\n    \n    # Precipitation\n    min_precip  = min(precip, na.rm = TRUE),\n    mean_precip = mean(precip, na.rm = TRUE),\n    max_precip  = max(precip, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt; \n    knitr::kable(align = \"c\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmin_temp\nmean_temp\nmax_temp\nmin_pressure\nmean_pressure\nmax_pressure\nmin_precip\nmean_precip\nmax_precip\n\n\n\n\n10.94\n55.26039\n100.04\n983.8\n1017.899\n1042.1\n0\n0.0044691\n1.21\n\n\n\n\n# Write a function\nsummarize_weather &lt;- function(data, vars) {\n  data |&gt;\n    summarize(\n      across({{ vars }},\n        list(\n          min  = \\(x) min(x, na.rm = TRUE),\n          mean = \\(x) mean(x, na.rm = TRUE),\n          max  = \\(x) max(x, na.rm = TRUE)\n        ),\n        .names = \"{.fn}_{.col}\"\n      )\n    ) |&gt;\n    mutate(across(where(is.numeric), \\(x) round(x, 2)))\n}\n\n# Test the function\nweather |&gt; \n    summarize_weather(c(temp, pressure, precip)) |&gt; \n    knitr::kable(align = \"c\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmin_temp\nmean_temp\nmax_temp\nmin_pressure\nmean_pressure\nmax_pressure\nmin_precip\nmean_precip\nmax_precip\n\n\n\n\n10.94\n55.26\n100.04\n983.8\n1017.9\n1042.1\n0\n0\n1.21\n\n\n\n\n\nIn the code chunk mentioned above, typing out all the calls can be tedious, and the code can become repetitive. This is a sign that we should convert our code into a function. Fortunately, we can quickly achieve this by inserting arguments inside doubled braces.\n\nConverts the user supplied variable that uses clock time (e.g., dep_time, arr_time, etc.) into a decimal time (i.e. hours + (minutes / 60)).\n\n\n# Solution\nflights |&gt;\n  select(year:sched_dep_time, arr_time, sched_arr_time) |&gt;\n  mutate(\n    hours = floor(arr_time / 100),\n    minutes = arr_time %% 100,\n    decimal_time = hours + (minutes / 60)\n  )\n\n# A tibble: 336,776 × 10\n    year month   day dep_time sched_dep_time arr_time sched_arr_time hours\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;    &lt;int&gt;          &lt;int&gt; &lt;dbl&gt;\n 1  2013     1     1      517            515      830            819     8\n 2  2013     1     1      533            529      850            830     8\n 3  2013     1     1      542            540      923            850     9\n 4  2013     1     1      544            545     1004           1022    10\n 5  2013     1     1      554            600      812            837     8\n 6  2013     1     1      554            558      740            728     7\n 7  2013     1     1      555            600      913            854     9\n 8  2013     1     1      557            600      709            723     7\n 9  2013     1     1      557            600      838            846     8\n10  2013     1     1      558            600      753            745     7\n# ℹ 336,766 more rows\n# ℹ 2 more variables: minutes &lt;dbl&gt;, decimal_time &lt;dbl&gt;\n\n# Write a function\nstandardize_time &lt;- function(data, time_var) {\n  data |&gt;\n    mutate(\n      # floor division\n      hours = floor({{ time_var }} / 100),\n      # extracting the remainder\n      minutes = {{ time_var }} %% 100,\n      # Convert the remainder to minutes; combine the results; round to 2\n      \"{{time_var}}\" := round(hours + minutes / 60, 2)\n    ) |&gt; \n        # Remove unnecessary columns\n        select(-hours, -minutes)\n}\n\n# OR ---------------------------------------------------------------------\n# We could simplify it further, thanks to Zakarie Hashi for the suggestion\nstandardise_time &lt;- function(data, time_var) {\n  data |&gt;\n    mutate(\n      # floor division, extracting the remainder,Convert the remainder to minutes; combine the results; round to 2\n      decimal_time = round(floor({{ time_var }} / 100) + ({{ time_var }} %% 100) / 60, 2)\n    )\n}\n\n# Test the function\nflights |&gt; \n    standardise_time(arr_time) |&gt; \n    slice_head(n = 5) \n\n# A tibble: 5 × 20\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n# ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, decimal_time &lt;dbl&gt;\n\n\nAs we demonstrated above, it is possible to complete this task with just one line of code, as suggested by Zakarie Hashi in a LinkedIn post from last year. In the function provided above, we utilized the floor() function to extract the hours and used modulo division to retrieve the remaining minutes. We then combined the outcomes and rounded our answer to two decimal places.\n\n\nConclusion\nIn this tutorial, we have shown you how to answer selected practice problems from section 25.3.5 exercises in R for Data Science, 2nd edition by Wickham et al. We have demonstrated various approaches for solving these questions wherever possible. Although we have highlighted some ways to solve these exercises, there are many other methods available. We encourage you to try them out and share your answers with us and our readers.\nHappy Coding 💪!"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Whether you’re an aspiring data scientist/analyst or a seasoned data science professional, my data science tutorials are designed to improve your R and Python coding skills. I assist aspiring and accomplished data scientists by offering tailored content based on the most up-to-date coding best practices. I strive to get you up and running and empower you to excel in your data science pursuits. Explore my tutorials and join my vibrant community of learners dedicated to continuous skill improvement.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nShowcasing the dplyr case_when() and case_match() Functions\n\n\n\n\n\n\n\nData Science\n\n\nData Wrangling\n\n\nR\n\n\n\n\nWhile reading Effective Pandas 2 by Matt Harrison, I learned about the new .case_when method in Pandas 2, which is a total life changer for pandas users who have longed for such a function for a long time. However, as an R programmer, I decided to review the dplyr case_when() documentation and learned that this “lifesaving” function has been updated.\n\n\n\n\n\n\nJan 4, 2024\n\n\nAlier Reng\n\n\n\n\n\n\n  \n\n\n\n\nSolving R 4 Data Science, 2nd-edition: Section 25.3.5 Exercises.\n\n\n\n\n\n\n\nData Science\n\n\nR\n\n\nTutorial\n\n\n\n\nTo practice R programming through hands-on exercises, as it is the best way to enhance your programming skills. In this tutorial, we will solve problems from Section 25.3.5 of the famous R 4 Data Science by Hadley Wickham et al.\n\n\n\n\n\n\nNov 11, 2023\n\n\nAlier Reng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "feeds.html",
    "href": "feeds.html",
    "title": "RSS feeds",
    "section": "",
    "text": "Latest content\nalierwaidatastudio.com/latest-content.xml\n\n\nCase studies\nalierwaidatastudio.com/case-studies/index.xml\n\n\nTutorials\nalierwaidatastudio.com/tutorials/index.xml"
  },
  {
    "objectID": "ts-and-cs.html",
    "href": "ts-and-cs.html",
    "title": "Terms and conditions",
    "section": "",
    "text": "The statements published on this blog reflect my personal views and opinions, not my employer’s."
  },
  {
    "objectID": "ts-and-cs.html#legal-disclaimer",
    "href": "ts-and-cs.html#legal-disclaimer",
    "title": "Terms and conditions",
    "section": "",
    "text": "The statements published on this blog reflect my personal views and opinions, not my employer’s."
  }
]